{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afdfbba",
   "metadata": {},
   "source": [
    "# Data Formulator with Ollama: Complete Setup and Usage Guide\n",
    "\n",
    "This notebook provides a comprehensive guide to setting up and using Data Formulator with Ollama for free, local data analysis and visualization.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Overview](#Overview)\n",
    "2. [Prerequisites](#prerequisites)\n",
    "3. [Installation](#installation)\n",
    "4. [Configuration](#configuration)\n",
    "5. [Running Data Formulator in Jupyter](#running)\n",
    "6. [Example Analysis](#example)\n",
    "7. [Troubleshooting](#troubleshooting)\n",
    "8. [Best Practices](#best-practices)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1464511",
   "metadata": {},
   "source": [
    "<h2 id=\"Overview\">1. Overview</h2>\n",
    "\n",
    "**Data Formulator** is a tool that bridges natural language and data visualization, allowing you to describe what you want to analyze and automatically generating appropriate visualizations.\n",
    "\n",
    "**Ollama** is a local AI inference engine that lets you run large language models on your machine for free.\n",
    "\n",
    "### System Requirements\n",
    "- **RAM**: 8GB minimum, 16GB recommended\n",
    "- **Storage**: 10GB+ free space\n",
    "- **OS**: macOS, Linux, or Windows\n",
    "- **Python**: 3.10+\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5113b",
   "metadata": {},
   "source": [
    "<h2 id=\"prerequisites\">2. prerequisites</h2>\n",
    "\n",
    "\n",
    "Before we begin, let's check if you have the necessary tools installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b04e1b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.16 (main, Dec 11 2024, 10:24:41) [Clang 14.0.6 ]\n",
      "Current working directory: /Users/soniacq/Urban/OSCUR-experiments\n",
      "Conda environment: profilers\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if we're in a conda environment\n",
    "if 'CONDA_DEFAULT_ENV' in os.environ:\n",
    "    print(f\"Conda environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "else:\n",
    "    print(\"Not in a conda environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224e98b",
   "metadata": {},
   "source": [
    "## 3. Installation\n",
    "\n",
    "### Step 3.1: Install Ollama\n",
    "\n",
    "First, let's check if Ollama is already installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1eda23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama is installed: ollama version is 0.5.7\n"
     ]
    }
   ],
   "source": [
    "# Check if Ollama is installed\n",
    "try:\n",
    "    result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ Ollama is installed: {result.stdout.strip()}\")\n",
    "        ollama_installed = True\n",
    "    else:\n",
    "        print(\"❌ Ollama not found\")\n",
    "        ollama_installed = False\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Ollama not found\")\n",
    "    ollama_installed = False\n",
    "\n",
    "if not ollama_installed:\n",
    "    print(\"\\nTo install Ollama:\")\n",
    "    print(\"macOS/Linux: curl -fsSL https://ollama.com/install.sh | sh\")\n",
    "    print(\"Windows: Download from https://ollama.com\")\n",
    "    print(\"\\nAfter installation, restart this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320da46",
   "metadata": {},
   "source": [
    "### Step 3.2: Install Data Formulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911a3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Data Formulator\n",
    "# !pip install data_formulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f5f96",
   "metadata": {},
   "source": [
    "### Step 3.3: Install Additional Dependencies for Jupyter Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c14291e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install packages for Jupyter integration\n",
    "!pip install requests pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a0362",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "### Step 4.1: Download and Set Up Ollama Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906d5e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Ollama models:\n",
      "NAME                      ID              SIZE      MODIFIED     \n",
      "llama3.2-vision:latest    085a1fdae525    7.9 GB    4 months ago    \n",
      "llama3.2-vision:11b       085a1fdae525    7.9 GB    4 months ago    \n",
      "\n",
      "✅ Suitable models found!\n"
     ]
    }
   ],
   "source": [
    "# Check available Ollama models\n",
    "if ollama_installed:\n",
    "    try:\n",
    "        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "        print(\"Current Ollama models:\")\n",
    "        print(result.stdout)\n",
    "        \n",
    "        # Check if we have any suitable models\n",
    "        if \"llama\" in result.stdout.lower():\n",
    "            print(\"✅ Suitable models found!\")\n",
    "        else:\n",
    "            print(\"⚠️  No suitable models found. Let's download one.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking models: {e}\")\n",
    "else:\n",
    "    print(\"Please install Ollama first (see Step 3.1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda27ce4",
   "metadata": {},
   "source": [
    "### Step 4.2: Download a Model (if needed)\n",
    "\n",
    "If you don't have a suitable model, uncomment and run the appropriate command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7e168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model download initiated. This may take several minutes...\n",
      "Check terminal for progress updates.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment ONE of these based on your system capabilities:\n",
    "\n",
    "# Lightweight option (1.3GB) - good for testing\n",
    "# !ollama pull llama3.2:1b\n",
    "\n",
    "# Balanced option (2GB) - recommended\n",
    "# !ollama pull llama3.2:3b\n",
    "\n",
    "# Larger option (7.9GB) - best performance if you have space\n",
    "# !ollama pull llama3.2-vision:11b\n",
    "\n",
    "print(\"Model download initiated. This may take several minutes...\")\n",
    "print(\"Check terminal for progress updates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e31892",
   "metadata": {},
   "source": [
    "### Step 4.3: Test Ollama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa61f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama server is running!\n",
      "Available models: 2\n",
      "  - llama3.2-vision:latest (7.9GB)\n",
      "  - llama3.2-vision:11b (7.9GB)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def check_ollama_server():\n",
    "    \"\"\"Check if Ollama server is running and get available models\"\"\"\n",
    "    try:\n",
    "        response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()['models']\n",
    "            print(\"✅ Ollama server is running!\")\n",
    "            print(f\"Available models: {len(models)}\")\n",
    "            for model in models:\n",
    "                print(f\"  - {model['name']} ({model['size']/1e9:.1f}GB)\")\n",
    "            return True, models\n",
    "        else:\n",
    "            print(f\"❌ Ollama server responded with status {response.status_code}\")\n",
    "            return False, []\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"❌ Ollama server is not running\")\n",
    "        print(\"Start it with: ollama serve\")\n",
    "        return False, []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error checking Ollama server: {e}\")\n",
    "        return False, []\n",
    "\n",
    "ollama_running, available_models = check_ollama_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117402c",
   "metadata": {},
   "source": [
    "If Ollama server is not running, you need to start it. Run this in a terminal:\n",
    "\n",
    "```bash\n",
    "ollama serve\n",
    "```\n",
    "\n",
    "Keep that terminal open - the server needs to keep running.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdcdbd1",
   "metadata": {},
   "source": [
    "## 5. Running Data Formulator in Jupyter\n",
    "\n",
    "### Step 5.1: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295a086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Formulator manager created\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "from IPython.display import IFrame, display, HTML\n",
    "import requests\n",
    "\n",
    "class DataFormulatorManager:\n",
    "    def __init__(self, port=5001):\n",
    "        self.port = port\n",
    "        self.process = None\n",
    "        self.thread = None\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start Data Formulator in background\"\"\"\n",
    "        def run_server():\n",
    "            try:\n",
    "                self.process = subprocess.Popen(\n",
    "                    ['data_formulator', '--port', str(self.port)],\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.PIPE,\n",
    "                    text=True\n",
    "                )\n",
    "                self.process.wait()\n",
    "            except Exception as e:\n",
    "                print(f\"Error starting Data Formulator: {e}\")\n",
    "        \n",
    "        self.thread = threading.Thread(target=run_server, daemon=True)\n",
    "        self.thread.start()\n",
    "        \n",
    "        print(f\"Starting Data Formulator on port {self.port}...\")\n",
    "        \n",
    "        # Wait for server to start\n",
    "        for i in range(30):  # Wait up to 30 seconds\n",
    "            try:\n",
    "                response = requests.get(f'http://localhost:{self.port}', timeout=1)\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"✅ Data Formulator is ready at http://localhost:{self.port}\")\n",
    "                    return True\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(1)\n",
    "            if i % 5 == 0:\n",
    "                print(f\"Still waiting... ({i}/30 seconds)\")\n",
    "        \n",
    "        print(\"❌ Data Formulator failed to start within 30 seconds\")\n",
    "        return False\n",
    "    \n",
    "    def display(self, width=1200, height=800):\n",
    "        \"\"\"Display Data Formulator in an iframe\"\"\"\n",
    "        return IFrame(f'http://localhost:{self.port}', width=width, height=height)\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the Data Formulator process\"\"\"\n",
    "        if self.process:\n",
    "            self.process.terminate()\n",
    "            print(\"Data Formulator stopped\")\n",
    "\n",
    "# Create manager instance\n",
    "df_manager = DataFormulatorManager()\n",
    "print(\"Data Formulator manager created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884f316",
   "metadata": {},
   "source": [
    "### Step 5.2: Start Data Formulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52adabf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Formulator on port 5001...\n",
      "Still waiting... (0/30 seconds)\n",
      "✅ Data Formulator is ready at http://localhost:5001\n",
      "\n",
      "🎉 Ready to configure Data Formulator!\n",
      "\n",
      "Model Configuration Settings:\n",
      "Provider: ollama\n",
      "Model: llama3.2-vision:latest\n",
      "API Base: http://localhost:11434\n",
      "API Key: (leave empty)\n"
     ]
    }
   ],
   "source": [
    "# Start Data Formulator\n",
    "if ollama_running and available_models:\n",
    "    success = df_manager.start()\n",
    "    if success:\n",
    "        print(\"\\n🎉 Ready to configure Data Formulator!\")\n",
    "        print(\"\\nModel Configuration Settings:\")\n",
    "        print(f\"Provider: ollama\")\n",
    "        print(f\"Model: {available_models[0]['name']}\")\n",
    "        print(f\"API Base: http://localhost:11434\")\n",
    "        print(f\"API Key: (leave empty)\")\n",
    "    else:\n",
    "        print(\"Failed to start Data Formulator. Check the troubleshooting section.\")\n",
    "else:\n",
    "    print(\"Please ensure Ollama is running and has models available first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079fff2",
   "metadata": {},
   "source": [
    "### Step 5.3: Display Data Formulator Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f09640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5001\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1115ba530>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Data Formulator embedded in the notebook\n",
    "try:\n",
    "    display(df_manager.display(width=1200, height=800))\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying Data Formulator: {e}\")\n",
    "    print(f\"You can access it directly at: http://localhost:{df_manager.port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f130971b-cec5-40ac-8040-96fd39444772",
   "metadata": {},
   "source": [
    "### Step 5.4: Stop Data Formulator\n",
    "To stop Data Formulator running on port 5001, the method depends on how it was started. Since it is running in the background or as a separate process:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d9a12-cdc7-41a3-b0b2-24bbec7a8237",
   "metadata": {},
   "source": [
    "🔍 Find the process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ffa7a04-77f4-4c5d-bea8-3ada29884b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMAND     PID    USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\n",
      "python3.1 20650 soniacq    6u  IPv4 0xe7f3176def2eb69d      0t0  TCP *:commplex-link (LISTEN)\n"
     ]
    }
   ],
   "source": [
    "!lsof -i :5001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e8361-5228-4a2e-90a7-9ec3ca5e1219",
   "metadata": {},
   "source": [
    "This will return something like:\n",
    "```\n",
    "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
    "python3  12345 user   10u  IPv4 123456      0t0  TCP *:5001 (LISTEN)\n",
    "```\n",
    "\n",
    "🛑 Kill the process:\n",
    "Use the PID (process ID) from the output (e.g., 12345 above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aae0b7c0-1a42-406e-bfcd-1ceb28aaa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to kill the process:\n",
    "#!kill 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c295c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Example Analysis\n",
    "\n",
    "Let's create some sample data and walk through a complete analysis workflow.\n",
    "\n",
    "### Step 6.1: Create Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dad03a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample dataset with 1000 records\n",
      "\n",
      "Dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>region</th>\n",
       "      <th>sales_amount</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>customer_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Books</td>\n",
       "      <td>South</td>\n",
       "      <td>52.913376</td>\n",
       "      <td>68</td>\n",
       "      <td>4.277368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>East</td>\n",
       "      <td>111.529378</td>\n",
       "      <td>45</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>North</td>\n",
       "      <td>251.784602</td>\n",
       "      <td>26</td>\n",
       "      <td>2.527938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Books</td>\n",
       "      <td>North</td>\n",
       "      <td>189.108088</td>\n",
       "      <td>48</td>\n",
       "      <td>3.974176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>Books</td>\n",
       "      <td>North</td>\n",
       "      <td>232.551075</td>\n",
       "      <td>18</td>\n",
       "      <td>4.512434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date product_category region  sales_amount  customer_age  \\\n",
       "0 2024-01-01            Books  South     52.913376            68   \n",
       "1 2024-01-02    Home & Garden   East    111.529378            45   \n",
       "2 2024-01-03      Electronics  North    251.784602            26   \n",
       "3 2024-01-04            Books  North    189.108088            48   \n",
       "4 2024-01-05            Books  North    232.551075            18   \n",
       "\n",
       "   customer_satisfaction  \n",
       "0               4.277368  \n",
       "1               5.000000  \n",
       "2               2.527938  \n",
       "3               3.974176  \n",
       "4               4.512434  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   date                   1000 non-null   datetime64[ns]\n",
      " 1   product_category       1000 non-null   object        \n",
      " 2   region                 1000 non-null   object        \n",
      " 3   sales_amount           1000 non-null   float64       \n",
      " 4   customer_age           1000 non-null   int64         \n",
      " 5   customer_satisfaction  1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(2)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "\n",
    "# Generate sample data\n",
    "data = {\n",
    "    'date': [datetime(2024, 1, 1) + timedelta(days=x) for x in range(n_records)],\n",
    "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home & Garden'], n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'sales_amount': np.random.exponential(100, n_records) + np.random.normal(50, 20, n_records),\n",
    "    'customer_age': np.random.normal(40, 15, n_records).astype(int),\n",
    "    'customer_satisfaction': np.random.normal(4.0, 0.8, n_records)\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_sample = pd.DataFrame(data)\n",
    "df_sample['sales_amount'] = np.maximum(df_sample['sales_amount'], 10)  # Ensure positive values\n",
    "df_sample['customer_age'] = np.clip(df_sample['customer_age'], 18, 80)  # Reasonable age range\n",
    "df_sample['customer_satisfaction'] = np.clip(df_sample['customer_satisfaction'], 1, 5)  # 1-5 scale\n",
    "\n",
    "print(f\"Created sample dataset with {len(df_sample)} records\")\n",
    "print(\"\\nDataset preview:\")\n",
    "display(df_sample.head())\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd63da0",
   "metadata": {},
   "source": [
    "### Step 6.2: Save Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6ac9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample data saved to: sample_sales_data.csv\n",
      "📍 Full path: /Users/soniacq/Urban/OSCUR-experiments/sample_sales_data.csv\n",
      "\n",
      "You can now upload this CSV file to Data Formulator above!\n"
     ]
    }
   ],
   "source": [
    "# Save the sample data for use in Data Formulator\n",
    "sample_data_path = 'sample_sales_data.csv'\n",
    "df_sample.to_csv(sample_data_path, index=False)\n",
    "\n",
    "print(f\"✅ Sample data saved to: {sample_data_path}\")\n",
    "print(f\"📍 Full path: {os.path.abspath(sample_data_path)}\")\n",
    "print(\"\\nYou can now upload this CSV file to Data Formulator above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af89ced",
   "metadata": {},
   "source": [
    "### Step 6.3: Analysis Examples\n",
    "\n",
    "Here are some example questions you can ask Data Formulator once you've uploaded the sample data:\n",
    "\n",
    "#### Basic Questions:\n",
    "- \"Show me sales by product category\"\n",
    "- \"What's the trend of sales over time?\"\n",
    "- \"Compare sales across different regions\"\n",
    "\n",
    "#### Advanced Questions: (Ollama couldn't perform this one)\n",
    "- \"Create a scatter plot of customer age vs sales amount, colored by region\"\n",
    "- \"Show me the correlation between customer satisfaction and sales amount\"\n",
    "- \"What's the average sales by month and product category?\"\n",
    "\n",
    "#### Complex Analysis: (Ollama couldn't perform this one)\n",
    "- \"Group customers by age brackets (18-30, 31-50, 51+) and show average satisfaction by category\"\n",
    "- \"Create a heatmap showing sales performance by region and product category\"\n",
    "- \"Show seasonal patterns in sales data with a moving average\"\n",
    "\n",
    "### Step 6.4: Configuration Reminder\n",
    "\n",
    "**Don't forget to configure your model in Data Formulator above:**\n",
    "\n",
    "1. Click \"Select Model\" in the Data Formulator interface\n",
    "2. Add a new model with these settings:\n",
    "   - **Provider**: `ollama`\n",
    "   - **Model**: Use the model name from your available models (check the output above)\n",
    "   - **API Base**: `http://localhost:11434`\n",
    "   - **API Key**: Leave empty\n",
    "3. Save the configuration\n",
    "4. Upload your CSV file\n",
    "5. Start asking questions!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fddb32-04c5-4d58-9278-17c945154d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34f4e319",
   "metadata": {},
   "source": [
    "## 7. Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### Issue 1: \"Address already in use\" - Port 5000 or 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7646fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 5000 is in use:\n",
      "COMMAND   PID    USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\n",
      "ControlCe 709 soniacq    7u  IPv4 0xe7f3176dec06d435      0t0  TCP *:commplex-main (LISTEN)\n",
      "ControlCe 709 soniacq    8u  IPv6 0xe7f31772b66d4fa5      0t0  TCP *:commplex-main (LISTEN)\n",
      "\n",
      "Port 5001 is in use:\n",
      "COMMAND     PID    USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME\n",
      "python3.1 20650 soniacq    6u  IPv4 0xe7f3176def2eb69d      0t0  TCP *:commplex-link (LISTEN)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_port_usage(port):\n",
    "    \"\"\"Check what's using a specific port\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['lsof', '-i', f':{port}'], capture_output=True, text=True)\n",
    "        if result.stdout:\n",
    "            print(f\"Port {port} is in use:\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(f\"Port {port} appears to be free\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"lsof command not available (Windows users: use netstat -an | findstr :5001)\")\n",
    "\n",
    "# Check common ports\n",
    "check_port_usage(5000)\n",
    "check_port_usage(5001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330da93",
   "metadata": {},
   "source": [
    "**Solution**: Use a different port:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3fa906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Data Formulator manager created on port 8080\n"
     ]
    }
   ],
   "source": [
    "# Try a different port\n",
    "df_manager_alt = DataFormulatorManager(port=8080)\n",
    "print(\"Alternative Data Formulator manager created on port 8080\")\n",
    "# Uncomment to start:\n",
    "# df_manager_alt.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140416a",
   "metadata": {},
   "source": [
    "#### Issue 2: Ollama Connection Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbdf90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Ollama Diagnostics\n",
      "==================================================\n",
      "✅ Ollama version: ollama version is 0.5.7\n",
      "✅ Ollama server is running\n",
      "✅ 2 models available\n",
      "   - llama3.2-vision:latest\n",
      "   - llama3.2-vision:11b\n",
      "✅ Ollama processes running: 1074\n",
      "2635\n"
     ]
    }
   ],
   "source": [
    "def diagnose_ollama():\n",
    "    \"\"\"Comprehensive Ollama diagnostics\"\"\"\n",
    "    print(\"🔍 Ollama Diagnostics\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check if Ollama is installed\n",
    "    try:\n",
    "        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)\n",
    "        print(f\"✅ Ollama version: {result.stdout.strip()}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Ollama not found. Install from https://ollama.com\")\n",
    "        return\n",
    "    \n",
    "    # Check if server is running\n",
    "    try:\n",
    "        response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"✅ Ollama server is running\")\n",
    "            models = response.json()['models']\n",
    "            print(f\"✅ {len(models)} models available\")\n",
    "            for model in models:\n",
    "                print(f\"   - {model['name']}\")\n",
    "        else:\n",
    "            print(f\"⚠️  Ollama server returned status {response.status_code}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"❌ Ollama server not running\")\n",
    "        print(\"   Start with: ollama serve\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "    \n",
    "    # Check processes\n",
    "    try:\n",
    "        result = subprocess.run(['pgrep', '-f', 'ollama'], capture_output=True, text=True)\n",
    "        if result.stdout:\n",
    "            print(f\"✅ Ollama processes running: {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(\"❌ No Ollama processes found\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Unable to check processes (pgrep not available)\")\n",
    "\n",
    "diagnose_ollama()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3648e3",
   "metadata": {},
   "source": [
    "#### Issue 3: Model Loading Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ec099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model inference...\n",
      "✅ Model llama3.2-vision:latest is working\n",
      "   Response: Hello there! It's nice to meet you. Is there something I can help you with or would you like to chat...\n",
      "✅ Model llama3.2-vision:11b is working\n",
      "   Response: Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?...\n"
     ]
    }
   ],
   "source": [
    "def test_model_inference(model_name):\n",
    "    \"\"\"Test if a model can perform inference\"\"\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": \"Hello, world!\",\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            'http://localhost:11434/api/generate',\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"✅ Model {model_name} is working\")\n",
    "            print(f\"   Response: {result.get('response', 'No response')[:100]}...\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Model {model_name} returned status {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error testing model {model_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test available models\n",
    "if available_models:\n",
    "    print(\"Testing model inference...\")\n",
    "    for model in available_models[:2]:  # Test first 2 models\n",
    "        test_model_inference(model['name'])\n",
    "else:\n",
    "    print(\"No models available to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb851141",
   "metadata": {},
   "source": [
    "#### Issue 4: Data Formulator Won't Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48bd99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Formulator is installed correctly\n",
      "\n",
      "Manual start command:\n",
      "data_formulator --port 5001\n"
     ]
    }
   ],
   "source": [
    "# Check Data Formulator installation\n",
    "try:\n",
    "    result = subprocess.run(['data_formulator', '--help'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ Data Formulator is installed correctly\")\n",
    "    else:\n",
    "        print(\"⚠️  Data Formulator installation might have issues\")\n",
    "        print(result.stderr)\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Data Formulator not found\")\n",
    "    print(\"   Install with: pip install data_formulator\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error checking Data Formulator: {e}\")\n",
    "\n",
    "# Alternative: Start manually\n",
    "print(\"\\nManual start command:\")\n",
    "print(\"data_formulator --port 5001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de72fd2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Best Practices\n",
    "\n",
    "- **Use a dedicated environment**: Keep your Data Formulator setup isolated to avoid conflicts.\n",
    "- **Monitor resource usage**: Keep an eye on RAM and CPU usage, especially with larger models.\n",
    "- **Backup your data**: Always keep copies of important datasets.\n",
    "\n",
    "Happy analyzing! 🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35710a95-59bb-44f9-8671-2320e4e277df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
